{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3e564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in ./venv/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./venv/lib/python3.13/site-packages (from chromadb) (1.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./venv/lib/python3.13/site-packages (from chromadb) (2.12.5)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./venv/lib/python3.13/site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./venv/lib/python3.13/site-packages (from chromadb) (2.2.6)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./venv/lib/python3.13/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.13/site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./venv/lib/python3.13/site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./venv/lib/python3.13/site-packages (from chromadb) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./venv/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./venv/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./venv/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./venv/lib/python3.13/site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./venv/lib/python3.13/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./venv/lib/python3.13/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./venv/lib/python3.13/site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./venv/lib/python3.13/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./venv/lib/python3.13/site-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./venv/lib/python3.13/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./venv/lib/python3.13/site-packages (from chromadb) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.13/site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./venv/lib/python3.13/site-packages (from chromadb) (4.26.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2026.1.4)\n",
      "Requirement already satisfied: packaging>=24.0 in ./venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.47.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.3)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./venv/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./venv/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./venv/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.13/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-google-genai in ./venv/lib/python3.13/site-packages (4.1.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./venv/lib/python3.13/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in ./venv/lib/python3.13/site-packages (from langchain-google-genai) (1.57.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in ./venv/lib/python3.13/site-packages (from langchain-google-genai) (1.2.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./venv/lib/python3.13/site-packages (from langchain-google-genai) (2.12.5)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.46.0 in ./venv/lib/python3.13/site-packages (from google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-chroma in ./venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: chromadb<2.0.0,>=1.3.5 in ./venv/lib/python3.13/site-packages (from langchain-chroma) (1.4.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.3 in ./venv/lib/python3.13/site-packages (from langchain-chroma) (1.2.7)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./venv/lib/python3.13/site-packages (from langchain-chroma) (2.2.6)\n",
      "Requirement already satisfied: build>=1.0.3 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.12.5)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./venv/lib/python3.13/site-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.26.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.3->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.3->langchain-chroma) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.3->langchain-chroma) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.3->langchain-chroma) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.3->langchain-chroma) (2.3.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in ./venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.30.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.47.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.12.19)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.33.3)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./venv/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in ./venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./venv/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./venv/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.36.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.13/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-groq in ./venv/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: groq<1.0.0,>=0.30.0 in ./venv/lib/python3.13/site-packages (from langchain-groq) (0.37.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in ./venv/lib/python3.13/site-packages (from langchain-groq) (1.2.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (2.12.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./venv/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install chromadb\n",
    "%pip install langchain-google-genai\n",
    "%pip install langchain-chroma\n",
    "%pip install langchain-groq\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00132af6",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c24ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a967c5",
   "metadata": {},
   "source": [
    "## 2. Initialize ChromaDB Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cc44605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB initialized at: ./unified_chroma_db\n",
      "üìä Available collections: ['project_attention_transformer_project']\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB with persistent storage\n",
    "DB_PATH = \"./unified_chroma_db\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=DB_PATH,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False,\n",
    "        allow_reset=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ChromaDB initialized at: {DB_PATH}\")\n",
    "print(f\"üìä Available collections: {[col.name for col in chroma_client.list_collections()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cb84d",
   "metadata": {},
   "source": [
    "## 3. Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "529149fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded: Google Gemini text-embedding-004\n",
      "üìê Task type: retrieval_query\n"
     ]
    }
   ],
   "source": [
    "# Initialize Google Gemini embedding model (same as ingestion pipelines)\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    task_type=\"retrieval_query\"  # Use retrieval_query for queries\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Embedding model loaded: Google Gemini text-embedding-004\")\n",
    "print(f\"üìê Task type: retrieval_query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed3b1c",
   "metadata": {},
   "source": [
    "## 4. Load Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45256b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded collection: project_attention_transformer_project\n",
      "üìä Total chunks: 30\n",
      "   üìÑ Document chunks: 25\n",
      "   üéôÔ∏è  Transcript chunks: 5\n"
     ]
    }
   ],
   "source": [
    "def load_unified_database(project_name: str = \"default_project\"):\n",
    "    \"\"\"\n",
    "    Load the unified ChromaDB collection for a project.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of the project\n",
    "        \n",
    "    Returns:\n",
    "        Chroma vector store object\n",
    "    \"\"\"\n",
    "    collection_name = f\"project_{project_name.lower().replace(' ', '_')}\"\n",
    "    \n",
    "    try:\n",
    "        # Load existing collection using LangChain wrapper\n",
    "        vectorstore = Chroma(\n",
    "            client=chroma_client,\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embedding_model\n",
    "        )\n",
    "        \n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        total_count = collection.count()\n",
    "        \n",
    "        # Get stats\n",
    "        all_data = collection.get(include=['metadatas'])\n",
    "        metadatas = all_data['metadatas']\n",
    "        \n",
    "        transcript_count = sum(1 for m in metadatas if m.get('source_type') == 'meeting_transcript')\n",
    "        document_count = sum(1 for m in metadatas if m.get('source_type') == 'document')\n",
    "        \n",
    "        print(f\"‚úÖ Loaded collection: {collection_name}\")\n",
    "        print(f\"üìä Total chunks: {total_count}\")\n",
    "        print(f\"   üìÑ Document chunks: {document_count}\")\n",
    "        print(f\"   üéôÔ∏è  Transcript chunks: {transcript_count}\")\n",
    "        \n",
    "        return vectorstore\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading collection '{collection_name}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example: Load your project\n",
    "PROJECT_NAME = \"attention_transformer_project\"  # Update to your project name\n",
    "db = load_unified_database(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fede536",
   "metadata": {},
   "source": [
    "## 5. Query and Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74e65a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded collection: project_attention_transformer_project\n",
      "üìä Total chunks: 30\n",
      "   üìÑ Document chunks: 25\n",
      "   üéôÔ∏è  Transcript chunks: 5\n",
      "\n",
      "üîç Query: Who Completed the english to german experiments\n",
      "üìä Retrieving top 3 chunks...\n",
      "‚úÖ Retrieved 3 chunks\n",
      "   1. üéôÔ∏è  Transcript: transformer_meeting\n",
      "   2. üìÑ Document: attention-is-all-you-need.pdf (p.10)\n",
      "   3. üìÑ Document: attention-is-all-you-need.pdf (p.8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='transcript_transformer_meeting_3', metadata={'speakers_in_chunk': '[\"Illia\", \"Ashish\", \"Niki\", \"Noam\", \"Jakob\"]', 'end_time': '00:02:45.500', 'project_name': 'attention_transformer_project', 'source_type': 'meeting_transcript', 'meeting_name': 'transformer_meeting', 'meeting_date': '2026-01-11', 'start_time': '00:01:50.500', 'chunk_index': 3, 'turn_count': 5}, page_content=\"Meeting: transformer_meeting\\n        Project: attention_transformer_project\\n        Date: 2026-01-11\\n        Time Range: 00:01:50.500 - 00:02:45.500\\n        Speakers: Illia, Ashish, Niki, Noam, Jakob\\n\\n        Transcript:\\n        Niki: I've finished the English-to-German experiments. The big model hit 28.4 BLEU. Even the base model at 27.3 BLEU beats the previous SOTA ensembles.\\nIllia: That‚Äôs incredible. And the English-to-French score? I saw we reached 41.8 BLEU. The training cost was only 3.5 days on 8 P100s.\\nJakob: We should also mention the constituency parsing results. It proves the Transformer generalizes well to structural tasks with limited data.\\nNoam: Agreed. The 4-layer Transformer we trained on WSJ data got 91.3 F1, which is impressive for a model not specifically tuned for parsing.\\nAshish: Finally, we need to clarify the positional encoding. We chose the sinusoidal version because it may allow the model to extrapolate to longer sequences.\"),\n",
       " Document(id='f3ae5494-3b05-405b-9b06-9786ce99df1f', metadata={'document_name': 'attention-is-all-you-need.pdf', 'page_number': 10, 'chunk_index': 21, 'original_content': '{\"raw_text\": \"7 Conclusion\\\\n\\\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\\\\n\\\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\\\\n\\\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\\\\n\\\\nThe code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\\\\n\\\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\", \"tables_html\": [], \"images_base64\": []}', 'has_vision_data': False, 'source_type': 'document', 'positions': '[{\"type\": \"Title\", \"coordinates\": {\"points\": [[297.6536560058594, 1012.6123244444444], [297.6536560058594, 1045.8212133333334], [511.0943298339844, 1045.8212133333334], [511.0943298339844, 1012.6123244444444]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[297.3792419433594, 1080.14256], [297.3792419433594, 1168.4220044444444], [1408.0157470703125, 1168.4220044444444], [1408.0157470703125, 1080.14256]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[297.9318542480469, 1186.2731155555555], [297.9318542480469, 1304.8553377777778], [1410.9105224609375, 1304.8553377777778], [1410.9105224609375, 1186.2731155555555]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[295.9335021972656, 1322.7036711111111], [295.9335021972656, 1441.2886711111107], [1412.54541015625, 1441.2886711111107], [1412.54541015625, 1322.7036711111111]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[292.3924255371094, 1459.1370044444443], [292.3924255371094, 1517.2797144444444], [1409.8258056640625, 1517.2797144444444], [1409.8258056640625, 1459.1370044444443]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[291.5016784667969, 1552.2043983333333], [291.5016784667969, 1610.3747822222222], [1405.9678955078125, 1610.3747822222222], [1405.9678955078125, 1552.2043983333333]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}]'}, page_content='7 Conclusion\\n\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\\n\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\\n\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\\n\\nThe code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\\n\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.'),\n",
       " Document(id='717d4e36-7c89-4124-80d8-5e50399dcd11', metadata={'chunk_index': 18, 'positions': '[{\"type\": \"Title\", \"coordinates\": {\"points\": [[297.5052185058594, 1030.5706577777778], [297.5052185058594, 1063.7795466666666], [456.0323791503906, 1063.7795466666666], [456.0323791503906, 1030.5706577777778]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"Title\", \"coordinates\": {\"points\": [[296.4135437011719, 1102.871065], [296.4135437011719, 1130.5449538888888], [610.598876953125, 1130.5449538888888], [610.598876953125, 1102.871065]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[300.0, 1161.0286711111112], [300.0, 1340.2192266666666], [1411.6092529296875, 1340.2192266666666], [1411.6092529296875, 1161.0286711111112]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[298.73382568359375, 1357.4587344444442], [298.73382568359375, 1478.5831033333332], [1412.306640625, 1478.5831033333332], [1412.306640625, 1357.4587344444442]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[296.6873474121094, 1494.5008933333334], [296.6873474121094, 1643.3858933333333], [1412.0120849609375, 1643.3858933333333], [1412.0120849609375, 1494.5008933333334]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}, {\"type\": \"NarrativeText\", \"coordinates\": {\"points\": [[295.337158203125, 1661.2370044444442], [295.337158203125, 1779.8192266666665], [1411.2901611328125, 1779.8192266666665], [1411.2901611328125, 1661.2370044444442]], \"system\": \"PixelSpace\", \"layout_width\": 1700, \"layout_height\": 2200}}]', 'page_number': 8, 'original_content': '{\"raw_text\": \"6 Results\\\\n\\\\n6.1 Machine Translation\\\\n\\\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big) in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0 BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is listed in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the competitive models.\\\\n\\\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, outperforming all of the previously published single models, at less than 1/4 the training cost of the previous state-of-the-art model. The Transformer (big) model trained for English-to-French used dropout rate Pdrop = 0.1, instead of 0.3.\\\\n\\\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We used beam search with a beam size of 4 and length penalty \\\\u03b1 = 0.6 [38]. These hyperparameters were chosen after experimentation on the development set. We set the maximum output length during inference to input length + 50, but terminate early when possible [38].\\\\n\\\\nTable 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature. We estimate the number of floating point operations used to train a model by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU 5.\", \"tables_html\": [], \"images_base64\": []}', 'source_type': 'document', 'document_name': 'attention-is-all-you-need.pdf', 'has_vision_data': False}, page_content='6 Results\\n\\n6.1 Machine Translation\\n\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big) in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0 BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is listed in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the competitive models.\\n\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, outperforming all of the previously published single models, at less than 1/4 the training cost of the previous state-of-the-art model. The Transformer (big) model trained for English-to-French used dropout rate Pdrop = 0.1, instead of 0.3.\\n\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We used beam search with a beam size of 4 and length penalty Œ± = 0.6 [38]. These hyperparameters were chosen after experimentation on the development set. We set the maximum output length during inference to input length + 50, but terminate early when possible [38].\\n\\nTable 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature. We estimate the number of floating point operations used to train a model by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU 5.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_unified_collection(\n",
    "    query: str,\n",
    "    project_name: str = \"default_project\",\n",
    "    k: int = 5,\n",
    "    filter_source_type: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Query the unified collection and retrieve relevant chunks.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        project_name: Name of the project\n",
    "        k: Number of results to retrieve\n",
    "        filter_source_type: Optional filter (\"document\" or \"meeting_transcript\")\n",
    "        \n",
    "    Returns:\n",
    "        List of retrieved chunks\n",
    "    \"\"\"\n",
    "    vectorstore = load_unified_database(project_name)\n",
    "    \n",
    "    if not vectorstore:\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nüîç Query: {query}\")\n",
    "    print(f\"üìä Retrieving top {k} chunks...\")\n",
    "    \n",
    "    # Build filter if specified\n",
    "    search_kwargs = {\"k\": k}\n",
    "    if filter_source_type:\n",
    "        search_kwargs[\"filter\"] = {\"source_type\": filter_source_type}\n",
    "        print(f\"üîé Filtering by source_type: {filter_source_type}\")\n",
    "    \n",
    "    # Create retriever and query\n",
    "    retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\n",
    "    retrieved_chunks = retriever.invoke(query)\n",
    "    \n",
    "    print(f\"‚úÖ Retrieved {len(retrieved_chunks)} chunks\")\n",
    "    \n",
    "    # Display chunk sources\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        source_type = chunk.metadata.get('source_type', 'unknown')\n",
    "        if source_type == 'meeting_transcript':\n",
    "            meeting = chunk.metadata.get('meeting_name', 'Unknown')\n",
    "            print(f\"   {i+1}. üéôÔ∏è  Transcript: {meeting}\")\n",
    "        else:\n",
    "            doc = chunk.metadata.get('document_name', 'Unknown')\n",
    "            page = chunk.metadata.get('page_number', 'N/A')\n",
    "            print(f\"   {i+1}. üìÑ Document: {doc} (p.{page})\")\n",
    "    \n",
    "    return retrieved_chunks\n",
    "\n",
    "\n",
    "# Test query\n",
    "query = \"Who Completed the english to german experiments\"\n",
    "retrieved_chunks = query_unified_collection(query, project_name=PROJECT_NAME, k=3)\n",
    "retrieved_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dad60d",
   "metadata": {},
   "source": [
    "## 6. Enhanced Citation Functions\n",
    "\n",
    "Support citations for both documents and transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5be6f7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Citation functions loaded\n"
     ]
    }
   ],
   "source": [
    "def extract_citations_with_metadata(answer_text, chunks_metadata):\n",
    "    \"\"\"\n",
    "    Extract citations and map to metadata for both documents and transcripts.\n",
    "    \n",
    "    Args:\n",
    "        answer_text: The generated answer with [CITE:X] markers\n",
    "        chunks_metadata: Dictionary mapping chunk IDs to metadata\n",
    "        \n",
    "    Returns:\n",
    "        List of citation dictionaries with source-specific metadata\n",
    "    \"\"\"\n",
    "    citation_pattern = r'\\[CITE:([0-9,\\s]+)\\]'\n",
    "    cited_chunks = re.findall(citation_pattern, answer_text)\n",
    "    \n",
    "    citations = []\n",
    "    unique_chunks = set()\n",
    "    \n",
    "    for cite_group in cited_chunks:\n",
    "        chunk_ids = [int(x.strip()) for x in cite_group.split(',')]\n",
    "        unique_chunks.update(chunk_ids)\n",
    "    \n",
    "    for chunk_id in sorted(unique_chunks):\n",
    "        metadata = chunks_metadata.get(chunk_id)\n",
    "        if metadata:\n",
    "            source_type = metadata.get(\"source_type\", \"document\")\n",
    "            \n",
    "            if source_type == \"meeting_transcript\":\n",
    "                # Transcript citation\n",
    "                citations.append({\n",
    "                    \"chunk_id\": str(chunk_id),\n",
    "                    \"source_type\": \"transcript\",\n",
    "                    \"meeting_name\": metadata.get(\"meeting_name\"),\n",
    "                    \"meeting_date\": metadata.get(\"meeting_date\"),\n",
    "                    \"start_time\": metadata.get(\"start_time\"),\n",
    "                    \"end_time\": metadata.get(\"end_time\"),\n",
    "                    \"speakers\": metadata.get(\"speakers\", [])\n",
    "                })\n",
    "            else:\n",
    "                # Document citation\n",
    "                citations.append({\n",
    "                    \"chunk_id\": str(chunk_id),\n",
    "                    \"source_type\": \"document\",\n",
    "                    \"document\": metadata.get(\"document\"),\n",
    "                    \"page\": metadata.get(\"page\"),\n",
    "                    \"positions\": metadata.get(\"positions\", [])\n",
    "                })\n",
    "    \n",
    "    return citations\n",
    "\n",
    "\n",
    "def format_answer_with_citations(answer_text, chunks_metadata):\n",
    "    \"\"\"\n",
    "    Replace [CITE:X] with appropriate format for documents and transcripts.\n",
    "    \n",
    "    Documents: [doc_name(p.X)]\n",
    "    Transcripts: [meeting_name(timestamp)]\n",
    "    \"\"\"\n",
    "    def replace_citation(match):\n",
    "        cite_group = match.group(1)\n",
    "        chunk_ids = [int(x.strip()) for x in cite_group.split(',')]\n",
    "        \n",
    "        # Group by source type\n",
    "        doc_chunks = []\n",
    "        transcript_chunks = []\n",
    "        \n",
    "        for chunk_id in chunk_ids:\n",
    "            metadata = chunks_metadata.get(chunk_id)\n",
    "            if metadata:\n",
    "                source_type = metadata.get(\"source_type\", \"document\")\n",
    "                if source_type == \"meeting_transcript\":\n",
    "                    transcript_chunks.append(metadata)\n",
    "                else:\n",
    "                    doc_chunks.append(metadata)\n",
    "        \n",
    "        # Format citations\n",
    "        citations = []\n",
    "        \n",
    "        # Format document citations\n",
    "        if doc_chunks:\n",
    "            doc_name = doc_chunks[0].get(\"document\", \"\").replace(\".pdf\", \"\")\n",
    "            pages = list(set(m.get(\"page\") for m in doc_chunks if m.get(\"page\")))\n",
    "            pages_str = \", \".join([f\"p.{p}\" for p in sorted(pages) if p != \"N/A\"])\n",
    "            if doc_name and pages_str:\n",
    "                citations.append(f\"{doc_name}({pages_str})\")\n",
    "        \n",
    "        # Format transcript citations\n",
    "        for transcript_meta in transcript_chunks:\n",
    "            meeting_name = transcript_meta.get(\"meeting_name\", \"Meeting\")\n",
    "            start_time = transcript_meta.get(\"start_time\", \"\")\n",
    "            if meeting_name:\n",
    "                time_suffix = f\"@{start_time}\" if start_time else \"\"\n",
    "                citations.append(f\"{meeting_name}{time_suffix}\")\n",
    "        \n",
    "        if citations:\n",
    "            return f\"[{', '.join(citations)}]\"\n",
    "        \n",
    "        return match.group(0)\n",
    "    \n",
    "    citation_pattern = r'\\[CITE:([0-9,\\s]+)\\]'\n",
    "    formatted_answer = re.sub(citation_pattern, replace_citation, answer_text)\n",
    "    return formatted_answer\n",
    "\n",
    "\n",
    "print(\"‚úÖ Citation functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf646f",
   "metadata": {},
   "source": [
    "## 7. Answer Generation with Unified Context\n",
    "\n",
    "Generate answers using both document and transcript chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8bdea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Answer generation function loaded\n"
     ]
    }
   ],
   "source": [
    "def generate_unified_answer(chunks, query):\n",
    "    \"\"\"\n",
    "    Generate answer with citations supporting both documents and transcripts.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of retrieved chunks (mix of documents and transcripts)\n",
    "        query: The user query\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with answer, raw_answer, and chunks_metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        llm = ChatGroq(\n",
    "            model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\", \n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        \n",
    "        context_parts = []\n",
    "        all_images = []\n",
    "        chunks_metadata = {}\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_id = i + 1\n",
    "            source_type = chunk.metadata.get(\"source_type\", \"document\")\n",
    "            \n",
    "            # Build chunk header\n",
    "            if source_type == \"meeting_transcript\":\n",
    "                meeting_name = chunk.metadata.get(\"meeting_name\", \"Meeting\")\n",
    "                meeting_date = chunk.metadata.get(\"meeting_date\", \"\")\n",
    "                start_time = chunk.metadata.get(\"start_time\", \"\")\n",
    "                speakers_json = chunk.metadata.get(\"speakers_in_chunk\", \"[]\")\n",
    "                speakers = json.loads(speakers_json) if isinstance(speakers_json, str) else speakers_json\n",
    "                \n",
    "                doc_header = f\"### [CHUNK {chunk_id}] - TRANSCRIPT ###\\n\"\n",
    "                doc_header += f\"Meeting: {meeting_name}\\n\"\n",
    "                doc_header += f\"Date: {meeting_date}\\n\"\n",
    "                doc_header += f\"Time: {start_time}\\n\"\n",
    "                doc_header += f\"Speakers: {', '.join(speakers)}\\n\\n\"\n",
    "                \n",
    "                # Store metadata for citation\n",
    "                chunks_metadata[chunk_id] = {\n",
    "                    \"source_type\": \"meeting_transcript\",\n",
    "                    \"meeting_name\": meeting_name,\n",
    "                    \"meeting_date\": meeting_date,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"end_time\": chunk.metadata.get(\"end_time\", \"\"),\n",
    "                    \"speakers\": speakers\n",
    "                }\n",
    "                \n",
    "                # Get transcript content\n",
    "                doc_body = chunk.page_content\n",
    "                \n",
    "            else:\n",
    "                # Document chunk\n",
    "                doc_header = f\"### [CHUNK {chunk_id}] - DOCUMENT ###\\n\"\n",
    "                doc_body = \"\"\n",
    "                \n",
    "                positions_str = chunk.metadata.get(\"positions\", \"[]\")\n",
    "                positions = json.loads(positions_str) if isinstance(positions_str, str) else positions_str\n",
    "                \n",
    "                # Store metadata for citation\n",
    "                chunks_metadata[chunk_id] = {\n",
    "                    \"source_type\": \"document\",\n",
    "                    \"page\": chunk.metadata.get(\"page_number\", \"N/A\"),\n",
    "                    \"document\": chunk.metadata.get(\"document_name\", \"document.pdf\"),\n",
    "                    \"positions\": positions\n",
    "                }\n",
    "                \n",
    "                # Extract content\n",
    "                if \"original_content\" in chunk.metadata:\n",
    "                    orig_data = json.loads(chunk.metadata[\"original_content\"])\n",
    "                    text = orig_data.get(\"raw_text\", \"\")\n",
    "                    tables = orig_data.get(\"tables_html\", [])\n",
    "                    \n",
    "                    doc_body += f\"TEXT CONTENT:\\n{text}\\n\"\n",
    "                    if tables:\n",
    "                        doc_body += \"\\nTABULAR DATA:\\n\" + \"\\n\".join(tables) + \"\\n\"\n",
    "                    \n",
    "                    all_images.extend(orig_data.get(\"images_base64\", []))\n",
    "                else:\n",
    "                    doc_body += chunk.page_content\n",
    "            \n",
    "            context_parts.append(doc_header + doc_body)\n",
    "\n",
    "        final_context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        instruction_prompt = f\"\"\"You are a precise research assistant. Answer the user query using ONLY the provided context.\n",
    "\n",
    "The context includes both DOCUMENT chunks (from PDFs) and TRANSCRIPT chunks (from meeting recordings).\n",
    "\n",
    "CITATION RULES:\n",
    "1. Add [CITE:X] citations ONLY after complete sentences or paragraphs\n",
    "2. NEVER add citations inside tables, lists, or mid-sentence\n",
    "3. For tables: Add a single citation AFTER the entire table\n",
    "4. Example: \"The results are shown below.\\n\\n[table here]\\n\\n[CITE:3]\"\n",
    "5. For information from multiple chunks, use [CITE:X, Y, Z] format\n",
    "6. You can cite both documents and transcripts - they are equally valid sources\n",
    "7. If information is not in the context, say \"I don't have information about that\"\n",
    "\n",
    "USER QUERY: {query}\n",
    "\n",
    "RESEARCH CONTEXT:\n",
    "{final_context}\n",
    "\n",
    "ANSWER (with [CITE:X] citations AFTER The end of the answer to summarize transcriptions:\"\"\"\n",
    "\n",
    "        message_content = [{\"type\": \"text\", \"text\": instruction_prompt}]\n",
    "        \n",
    "        # Add images from document chunks (transcripts don't have images)\n",
    "        for img_b64 in all_images[:5]:\n",
    "            message_content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_b64}\"}\n",
    "            })\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=message_content)])\n",
    "        \n",
    "        formatted_answer = format_answer_with_citations(response.content, chunks_metadata)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": formatted_answer,\n",
    "            \"raw_answer\": response.content,\n",
    "            \"chunks_metadata\": chunks_metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Generation failed: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"Error generating response\",\n",
    "            \"raw_answer\": \"\",\n",
    "            \"chunks_metadata\": {}\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Answer generation function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe1330",
   "metadata": {},
   "source": [
    "## 8. Run Complete Query Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04caa7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ UNIFIED QUERY PIPELINE\n",
      "================================================================================\n",
      "‚úÖ Loaded collection: project_attention_transformer_project\n",
      "üìä Total chunks: 30\n",
      "   üìÑ Document chunks: 25\n",
      "   üéôÔ∏è  Transcript chunks: 5\n",
      "\n",
      "üîç Query: Who worked on the English-to-German experiments? what are the detailed results of the work\n",
      "üìä Retrieving top 3 chunks...\n",
      "‚úÖ Retrieved 3 chunks\n",
      "   1. üéôÔ∏è  Transcript: transformer_meeting\n",
      "   2. üìÑ Document: attention-is-all-you-need.pdf (p.7)\n",
      "   3. üìÑ Document: attention-is-all-you-need.pdf (p.8)\n",
      "\n",
      "ü§ñ Generating answer with Llama 4 Scout...\n",
      "\n",
      "================================================================================\n",
      "üìù ANSWER:\n",
      "================================================================================\n",
      "Niki worked on the English-to-German experiments [transformer_meeting@00:01:50.500]. The detailed results of the work are as follows: The big Transformer model achieved a BLEU score of 28.4, outperforming the best previously reported models, including ensembles, by more than 2.0 BLEU. This establishes a new state-of-the-art BLEU score. The base model also performed well, beating the previous SOTA ensembles with a BLEU score of 27.3. The training cost for the big model was 3.5 days on 8 P100 GPUs [attention-is-all-you-need(p.8), transformer_meeting@00:01:50.500].\n",
      "\n",
      "The experiments used the WMT 2014 English-German dataset, consisting of about 4.5 million sentence pairs, and byte-pair encoding with a shared source-target vocabulary of about 37,000 tokens [attention-is-all-you-need(p.7)]. The results are summarized in Table 2, which compares the translation quality and training costs to other model architectures from the literature [attention-is-all-you-need(p.8)]. \n",
      "\n",
      "[attention-is-all-you-need(p.8), transformer_meeting@00:01:50.500]\n",
      "\n",
      "================================================================================\n",
      "üìö CITATIONS:\n",
      "================================================================================\n",
      "\n",
      "üéôÔ∏è  Chunk 1 - Transcript Citation:\n",
      "   Meeting: transformer_meeting\n",
      "   Date: 2026-01-11\n",
      "   Time: 00:01:50.500 - 00:02:45.500\n",
      "   Speakers: Illia, Ashish, Niki, Noam, Jakob\n",
      "\n",
      "üìÑ Chunk 2 - Document Citation:\n",
      "   Document: attention-is-all-you-need.pdf\n",
      "   Page: 7\n",
      "   Positions: 5 elements\n",
      "\n",
      "üìÑ Chunk 3 - Document Citation:\n",
      "   Document: attention-is-all-you-need.pdf\n",
      "   Page: 8\n",
      "   Positions: 6 elements\n",
      "\n",
      "================================================================================\n",
      "‚úÖ QUERY PIPELINE COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURE YOUR QUERY HERE ===\n",
    "\n",
    "# Your question\n",
    "QUERY = \"Who worked on the English-to-German experiments? what are the detailed results of the work\"\n",
    "\n",
    "# Project name (should match your ingestion pipelines)\n",
    "PROJECT_NAME = \"attention_transformer_project\"\n",
    "\n",
    "# Number of chunks to retrieve\n",
    "K_RESULTS = 3\n",
    "\n",
    "# Optional: Filter by source type (None, \"document\", or \"meeting_transcript\")\n",
    "FILTER_SOURCE = None  # Set to \"document\" or \"meeting_transcript\" to filter\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ UNIFIED QUERY PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Retrieve chunks\n",
    "retrieved_chunks = query_unified_collection(\n",
    "    query=QUERY,\n",
    "    project_name=PROJECT_NAME,\n",
    "    k=K_RESULTS,\n",
    "    filter_source_type=FILTER_SOURCE\n",
    ")\n",
    "\n",
    "if not retrieved_chunks:\n",
    "    print(\"‚ùå No chunks retrieved\")\n",
    "else:\n",
    "    # Step 2: Generate answer\n",
    "    print(f\"\\nü§ñ Generating answer with Llama 4 Scout...\")\n",
    "    result = generate_unified_answer(retrieved_chunks, QUERY)\n",
    "    \n",
    "    # Step 3: Extract citations\n",
    "    citations = extract_citations_with_metadata(result[\"raw_answer\"], result[\"chunks_metadata\"])\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìù ANSWER:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result[\"answer\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö CITATIONS:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for cite in citations:\n",
    "        if cite['source_type'] == 'document':\n",
    "            print(f\"\\nüìÑ Chunk {cite['chunk_id']} - Document Citation:\")\n",
    "            print(f\"   Document: {cite['document']}\")\n",
    "            print(f\"   Page: {cite['page']}\")\n",
    "            print(f\"   Positions: {len(cite['positions'])} elements\")\n",
    "        else:\n",
    "            print(f\"\\nüéôÔ∏è  Chunk {cite['chunk_id']} - Transcript Citation:\")\n",
    "            print(f\"   Meeting: {cite['meeting_name']}\")\n",
    "            print(f\"   Date: {cite['meeting_date']}\")\n",
    "            print(f\"   Time: {cite['start_time']} - {cite['end_time']}\")\n",
    "            print(f\"   Speakers: {', '.join(cite['speakers'])}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ QUERY PIPELINE COMPLETE!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1aeee",
   "metadata": {},
   "source": [
    "## 9. Export Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "671e7620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported results to: unified_query_results.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def export_query_results(chunks, answer_result, filename=\"unified_query_results.json\"):\n",
    "    \"\"\"\n",
    "    Export query results including chunks, answer, and citations to JSON.\n",
    "    \n",
    "    Args:\n",
    "        chunks: Retrieved chunks\n",
    "        answer_result: Result from generate_unified_answer()\n",
    "        filename: Output filename\n",
    "    \"\"\"\n",
    "    export_data = {\n",
    "        \"query\": QUERY,\n",
    "        \"timestamp\": str(pd.Timestamp.now()) if 'pd' in dir() else None,\n",
    "        \"answer\": answer_result[\"answer\"],\n",
    "        \"raw_answer\": answer_result[\"raw_answer\"],\n",
    "        \"chunks\": [],\n",
    "        \"citations\": []\n",
    "    }\n",
    "    \n",
    "    # Export chunks\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = i + 1\n",
    "        source_type = chunk.metadata.get(\"source_type\", \"document\")\n",
    "        \n",
    "        chunk_data = {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"source_type\": source_type,\n",
    "            \"content\": chunk.page_content,\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "        \n",
    "        if source_type == \"meeting_transcript\":\n",
    "            chunk_data[\"metadata\"] = {\n",
    "                \"meeting_name\": chunk.metadata.get(\"meeting_name\"),\n",
    "                \"meeting_date\": chunk.metadata.get(\"meeting_date\"),\n",
    "                \"start_time\": chunk.metadata.get(\"start_time\"),\n",
    "                \"end_time\": chunk.metadata.get(\"end_time\"),\n",
    "                \"speakers\": json.loads(chunk.metadata.get(\"speakers_in_chunk\", \"[]\"))\n",
    "            }\n",
    "        else:\n",
    "            chunk_data[\"metadata\"] = {\n",
    "                \"document_name\": chunk.metadata.get(\"document_name\"),\n",
    "                \"page_number\": chunk.metadata.get(\"page_number\"),\n",
    "                \"has_tables\": \"original_content\" in chunk.metadata and \"tables_html\" in json.loads(chunk.metadata[\"original_content\"]),\n",
    "                \"has_images\": \"original_content\" in chunk.metadata and \"images_base64\" in json.loads(chunk.metadata[\"original_content\"])\n",
    "            }\n",
    "        \n",
    "        export_data[\"chunks\"].append(chunk_data)\n",
    "    \n",
    "    # Export citations\n",
    "    citations = extract_citations_with_metadata(answer_result[\"raw_answer\"], answer_result[\"chunks_metadata\"])\n",
    "    export_data[\"citations\"] = citations\n",
    "    \n",
    "    # Save to file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ Exported results to: {filename}\")\n",
    "\n",
    "\n",
    "# Export results\n",
    "if retrieved_chunks and result:\n",
    "    export_query_results(retrieved_chunks, result, \"unified_query_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7757c",
   "metadata": {},
   "source": [
    "## 10. Advanced Query Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbbe6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è  TRANSCRIPT-ONLY QUERY:\n",
      "================================================================================\n",
      "‚úÖ Loaded collection: project_attention_transformer_project\n",
      "üìä Total chunks: 30\n",
      "   üìÑ Document chunks: 25\n",
      "   üéôÔ∏è  Transcript chunks: 5\n",
      "\n",
      "üîç Query: what was discussed in the meeting\n",
      "üìä Retrieving top 3 chunks...\n",
      "üîé Filtering by source_type: meeting_transcript\n",
      "‚úÖ Retrieved 3 chunks\n",
      "   1. üéôÔ∏è  Transcript: transformer_meeting\n",
      "   2. üéôÔ∏è  Transcript: transformer_meeting\n",
      "   3. üéôÔ∏è  Transcript: transformer_meeting\n",
      "\n",
      "================================================================================\n",
      "üìù ANSWER:\n",
      "================================================================================\n",
      "The meeting discussed several aspects of the transformer model, including its performance on various tasks and its architecture. The discussion began with Niki sharing the results of English-to-German experiments, where the big model achieved 28.4 BLEU and the base model achieved 27.3 BLEU, beating previous state-of-the-art ensembles [transformer_meeting@00:01:50.500, transformer_meeting@00:01:15.200]. \n",
      "\n",
      "The group also discussed the English-to-French score, which reached 41.8 BLEU with a training cost of only 3.5 days on 8 P100s [transformer_meeting@00:01:50.500, transformer_meeting@00:01:15.200]. Additionally, they touched on the constituency parsing results, where a 4-layer Transformer trained on WSJ data achieved 91.3 F1, which is impressive for a model not specifically tuned for parsing [transformer_meeting@00:01:50.500, transformer_meeting@00:02:32.100].\n",
      "\n",
      "The architecture of the transformer model was also discussed, including the encoder layer, which consists of two sub-layers: multi-head self-attention and a position-wise feed-forward network, along with residual connections and layer normalization [transformer_meeting@00:01:15.200]. The group decided on the sinusoidal version of positional encoding, which may allow the model to extrapolate to longer sequences [transformer_meeting@00:01:50.500, transformer_meeting@00:02:32.100].\n",
      "\n",
      "[transformer_meeting@00:01:50.500, transformer_meeting@00:01:15.200, transformer_meeting@00:02:32.100]\n",
      "\n",
      "================================================================================\n",
      "üìö CITATIONS:\n",
      "================================================================================\n",
      "\n",
      "üéôÔ∏è  Chunk 1 - Transcript Citation:\n",
      "   Meeting: transformer_meeting\n",
      "   Date: 2026-01-11\n",
      "   Time: 00:01:50.500 - 00:02:45.500\n",
      "   Speakers: Illia, Ashish, Niki, Noam, Jakob\n",
      "\n",
      "üéôÔ∏è  Chunk 2 - Transcript Citation:\n",
      "   Meeting: transformer_meeting\n",
      "   Date: 2026-01-11\n",
      "   Time: 00:01:15.200 - 00:02:05.200\n",
      "   Speakers: Ashish, Illia, Niki, Noam, Jakob\n",
      "\n",
      "üéôÔ∏è  Chunk 3 - Transcript Citation:\n",
      "   Meeting: transformer_meeting\n",
      "   Date: 2026-01-11\n",
      "   Time: 00:02:32.100 - 00:02:58.200\n",
      "   Speakers: Niki, Noam, Ashish\n"
     ]
    }
   ],
   "source": [
    "# Example: Query only transcripts\n",
    "print(\"üéôÔ∏è  TRANSCRIPT-ONLY QUERY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "transcript_chunks = query_unified_collection(\n",
    "    query=\"what was discussed in the meeting\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    k=3,\n",
    "    filter_source_type=\"meeting_transcript\"\n",
    ")\n",
    "\n",
    "if transcript_chunks:\n",
    "    transcript_result = generate_unified_answer(transcript_chunks, \"what was discussed in the meeting\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìù ANSWER:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(transcript_result[\"answer\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö CITATIONS:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "    citations = extract_citations_with_metadata(transcript_result[\"raw_answer\"], transcript_result[\"chunks_metadata\"])\n",
    "\n",
    "    for cite in citations:\n",
    "        print(f\"\\nüéôÔ∏è  Chunk {cite['chunk_id']} - Transcript Citation:\")\n",
    "        print(f\"   Meeting: {cite['meeting_name']}\")\n",
    "        print(f\"   Date: {cite['meeting_date']}\")\n",
    "        print(f\"   Time: {cite['start_time']} - {cite['end_time']}\")\n",
    "        print(f\"   Speakers: {', '.join(cite['speakers'])}\")\n",
    "\n",
    "else:\n",
    "    print(\"Chunks Not retrieved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c71bf71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ DOCUMENT-ONLY QUERY:\n",
      "================================================================================\n",
      "‚úÖ Loaded collection: project_attention_transformer_project\n",
      "üìä Total chunks: 30\n",
      "   üìÑ Document chunks: 25\n",
      "   üéôÔ∏è  Transcript chunks: 5\n",
      "\n",
      "üîç Query: transformer architecture details\n",
      "üìä Retrieving top 3 chunks...\n",
      "üîé Filtering by source_type: document\n",
      "‚úÖ Retrieved 3 chunks\n",
      "   1. üìÑ Document: attention-is-all-you-need.pdf (p.2)\n",
      "   2. üìÑ Document: attention-is-all-you-need.pdf (p.2)\n",
      "   3. üìÑ Document: attention-is-all-you-need.pdf (p.2)\n",
      "\n",
      "================================================================================\n",
      "üìù ANSWER:\n",
      "================================================================================\n",
      "The Transformer architecture is based on an encoder-decoder structure, which maps an input sequence of symbol representations to a sequence of continuous representations, and then generates an output sequence of symbols one element at a time [attention-is-all-you-need(p.2)]. \n",
      "\n",
      "The Transformer model consists of stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder takes in a sequence of symbol representations and outputs a sequence of continuous representations. The decoder then generates an output sequence of symbols, one element at a time, consuming the previously generated symbols as additional input [attention-is-all-you-need(p.2)].\n",
      "\n",
      "The Transformer architecture relies entirely on an attention mechanism to draw global dependencies between input and output, allowing for significantly more parallelization. This is in contrast to recurrent neural networks, which have a sequential nature that precludes parallelization within training examples [attention-is-all-you-need(p.2)].\n",
      "\n",
      "The Transformer model uses multi-head attention, which relates different positions of a single sequence to compute a representation of the sequence. This allows the model to learn dependencies between distant positions more effectively [attention-is-all-you-need(p.2)].\n",
      "\n",
      "The architecture of the Transformer model is shown in the figure, which includes the encoder and decoder components, with their respective layers and attention mechanisms.\n",
      "\n",
      "[attention-is-all-you-need(p.2)]\n",
      "\n",
      "================================================================================\n",
      "üìö CITATIONS:\n",
      "================================================================================\n",
      "\n",
      "üìÑ Chunk 1 - Document Citation:\n",
      "   Document: attention-is-all-you-need.pdf\n",
      "   Page: 2\n",
      "   Positions: 6 elements\n",
      "\n",
      "üìÑ Chunk 2 - Document Citation:\n",
      "   Document: attention-is-all-you-need.pdf\n",
      "   Page: 2\n",
      "   Positions: 5 elements\n",
      "\n",
      "üìÑ Chunk 3 - Document Citation:\n",
      "   Document: attention-is-all-you-need.pdf\n",
      "   Page: 2\n",
      "   Positions: 5 elements\n"
     ]
    }
   ],
   "source": [
    "# Example: Query only documents\n",
    "print(\"\\nüìÑ DOCUMENT-ONLY QUERY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "doc_chunks = query_unified_collection(\n",
    "    query=\"transformer architecture details\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    k=3,\n",
    "    filter_source_type=\"document\"\n",
    ")\n",
    "\n",
    "if doc_chunks:\n",
    "    doc_result = generate_unified_answer(doc_chunks, \"transformer architecture details\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìù ANSWER:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(doc_result[\"answer\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìö CITATIONS:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "    citations = extract_citations_with_metadata(doc_result[\"raw_answer\"], doc_result[\"chunks_metadata\"])\n",
    "\n",
    "    for cite in citations:\n",
    "        print(f\"\\nüìÑ Chunk {cite['chunk_id']} - Document Citation:\")\n",
    "        print(f\"   Document: {cite['document']}\")\n",
    "        print(f\"   Page: {cite['page']}\")\n",
    "        print(f\"   Positions: {len(cite['positions'])} elements\")\n",
    "\n",
    "else:\n",
    "    print(\"Chunks Not retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38634e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Attempting to backup collection metadata...\n",
      "‚úÖ Backed up metadata to: backup_project_attention_transformer_project_metadata.json\n",
      "\n",
      "‚ö†Ô∏è  Deleting corrupted collection: project_attention_transformer_project\n",
      "‚úÖ Collection deleted\n",
      "\n",
      "üìù Next steps:\n",
      "   1. Re-run document ingestion: 8_multi_modal_rag.ipynb\n",
      "      PROJECT_NAME = 'attention_transformer_project'\n",
      "   2. Re-run transcript ingestion: transcript_ingestion.ipynb\n",
      "      PROJECT_NAME = 'attention_transformer_project'\n"
     ]
    }
   ],
   "source": [
    "def backup_and_reset_collection(project_name: str):\n",
    "    \"\"\"\n",
    "    Backup metadata and reset corrupted collection.\n",
    "    \"\"\"\n",
    "    collection_name = f\"project_{project_name.lower().replace(' ', '_')}\"\n",
    "    \n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        \n",
    "        # Try to get metadata before deletion\n",
    "        print(f\"üîç Attempting to backup collection metadata...\")\n",
    "        try:\n",
    "            all_data = collection.get(include=['metadatas'])\n",
    "            backup_file = f\"backup_{collection_name}_metadata.json\"\n",
    "            \n",
    "            with open(backup_file, 'w') as f:\n",
    "                json.dump({\n",
    "                    'ids': all_data['ids'],\n",
    "                    'metadatas': all_data['metadatas']\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ Backed up metadata to: {backup_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not backup (collection too corrupted): {e}\")\n",
    "        \n",
    "        # Delete corrupted collection\n",
    "        print(f\"\\n‚ö†Ô∏è  Deleting corrupted collection: {collection_name}\")\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "        print(f\"‚úÖ Collection deleted\")\n",
    "        \n",
    "        print(f\"\\nüìù Next steps:\")\n",
    "        print(f\"   1. Re-run document ingestion: 8_multi_modal_rag.ipynb\")\n",
    "        print(f\"      PROJECT_NAME = '{project_name}'\")\n",
    "        print(f\"   2. Re-run transcript ingestion: transcript_ingestion.ipynb\")\n",
    "        print(f\"      PROJECT_NAME = '{project_name}'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Run this to reset\n",
    "backup_and_reset_collection(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044638b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This unified query pipeline provides:\n",
    "\n",
    "‚úÖ **Unified Querying**: Query both documents and transcripts together  \n",
    "‚úÖ **Source-Aware Citations**: Different citation formats for documents vs transcripts  \n",
    "‚úÖ **Document Citations**: `[doc_name(p.X)]` with page numbers and positions  \n",
    "‚úÖ **Transcript Citations**: `[meeting_name@timestamp]` with meeting metadata  \n",
    "‚úÖ **Mixed Results**: AI can combine information from both sources  \n",
    "‚úÖ **Filtering Options**: Query all sources or filter by type  \n",
    "‚úÖ **Vision Support**: Process images from document chunks  \n",
    "‚úÖ **Export Results**: Save answers and citations to JSON  \n",
    "\n",
    "**Citation Formats:**\n",
    "- **Documents**: `[attention-is-all-you-need(p.3, p.5)]`\n",
    "- **Transcripts**: `[Project Kickoff Meeting@00:15:30]`\n",
    "- **Mixed**: `[attention-is-all-you-need(p.3), Project Kickoff Meeting@00:15:30]`\n",
    "\n",
    "**Next Steps:**\n",
    "1. Update `PROJECT_NAME` to match your ingestion pipelines\n",
    "2. Modify `QUERY` to ask your questions\n",
    "3. Run the pipeline to get answers with mixed sources\n",
    "4. Export results for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
